{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from models.pcn import *\n",
    "from models.pccn import *\n",
    "import os\n",
    "import open3d_util\n",
    "\n",
    "print(tf.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagenerator import DataGenerator\n",
    "\n",
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "complete_dir = \"data/complete/\"\n",
    "ds_train = DataGenerator(get_file_paths(complete_dir), complete_dir)\n",
    "print((ds_train[2][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_2 import Dataloader\n",
    "complete_dir = \"data/complete/\"\n",
    "ds_valid = Dataloader(complete_dir, is_training=False, batch_size=8)\n",
    "print(ds_valid.counter)\n",
    "ds_iter = iter(ds_valid)\n",
    "# batch = next(ds_iter)\n",
    "# print(batch[0].shape,batch[1],batch[2].shape)\n",
    "# print(sum(batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_valid.list_pcd_path)//8)\n",
    "c = 0\n",
    "for id, data in enumerate(ds_valid):\n",
    "    assert sum(data[1]) == data[0].shape[1]\n",
    "    c+=1\n",
    "    if c % 10: print(\"-\",end=\" \")\n",
    "    # print(data[0].shape, end=\" | \")\n",
    "print(c, ds_iter.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Geek:\n",
    "    def __call__(self):\n",
    "        print('Hello GeeksforGeeks')\n",
    "\n",
    "geek = Geek()\n",
    "geek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 21:51:15.866133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:15.866168: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 21:51:18.390522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.390646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.390747: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.390848: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.390946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.391045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.391149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-25 21:51:18.391366: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-25 21:51:18.391726: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from dataloader import Dataloader\n",
    "ds_train = Dataloader(complete_dir=\"data/complete/\", is_training=True, batch_size=1)\n",
    "ds_train = tf.data.Dataset.from_generator(ds_train, output_types=(tf.float32, tf.int32, tf.float32), output_shapes=((), (), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 21:51:20.976028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-07-25 21:51:21.065970: W tensorflow/core/framework/op_kernel.cc:1680] Invalid argument: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n",
      "[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n",
      "  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n",
      "  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n",
      "  ...\n",
      "  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n",
      "  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n",
      "  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 900, in generator_py_func\n",
      "    six.reraise(\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/six.py\", line 702, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n",
      "[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n",
      "  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n",
      "  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n",
      "  ...\n",
      "  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n",
      "  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n",
      "  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n  ...\n  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\nTraceback (most recent call last):\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'tensorflow.python.framework.ops.EagerTensor'>.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 900, in generator_py_func\n    six.reraise(\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/six.py\", line 702, in reraise\n    raise value.with_traceback(tb)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n  ...\n  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/wrs/colab/PCC-Net/tf_playground.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wrs/colab/PCC-Net/tf_playground.ipynb#ch0000022?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m (a,b,c) \u001b[39min\u001b[39;00m ds_train\u001b[39m.\u001b[39mrepeat()\u001b[39m.\u001b[39mbatch(\u001b[39m8\u001b[39m)\u001b[39m.\u001b[39mtake(\u001b[39m10\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wrs/colab/PCC-Net/tf_playground.ipynb#ch0000022?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(a\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:761\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    760\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    762\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:744\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 744\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    745\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    746\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    747\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    749\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    750\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:2728\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2726\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   2727\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 2728\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   2729\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   2730\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6940\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6941\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n  ...\n  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\nTraceback (most recent call last):\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: <class 'tensorflow.python.framework.ops.EagerTensor'>.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 900, in generator_py_func\n    six.reraise(\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/six.py\", line 702, in reraise\n    raise value.with_traceback(tb)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 898, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 381, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/wrs/.local/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py\", line 282, in assert_shallow_structure\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, tf.int32, tf.float32), but the yielded element was tf.Tensor(\n[[[ 1.0383280e-03 -1.5828928e-03  3.7101896e-03]\n  [ 6.1125058e-05 -7.3752232e-04  2.3326376e-03]\n  [ 9.6225485e-05 -5.3882645e-04  1.2442997e-03]\n  ...\n  [-9.0772845e-02  5.4567087e-02  4.6876539e-02]\n  [-9.0408914e-02  5.4436173e-02  4.6672925e-02]\n  [-8.8086993e-02  5.4665931e-02  4.6051532e-02]]], shape=(1, 1420, 3), dtype=float32).\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "for (a,b,c) in ds_train.repeat().batch(8).take(10):\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(s, shape):\n",
    "    print(s.center(35), \":\",shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "len(get_file_paths(\"data/complete/\", training=0))\n",
    "\n",
    "def xform(dir):\n",
    "    return dir.replace(\"complete\", \"partial\")\n",
    "\n",
    "def get_pcds_np(complete_dir, training=True):\n",
    "    partial, npts, complete = [], [], []\n",
    "    cnt = 0\n",
    "    for pcd_path in get_file_paths(complete_dir, training=True):\n",
    "        complete.append(open3d_util.read_pcd(os.path.join(complete_dir, pcd_path)))\n",
    "        partial.append(open3d_util.read_pcd(os.path.join(xform(complete_dir), xform(pcd_path))))\n",
    "        npts.append(len(partial[-1]))\n",
    "        cnt+=1\n",
    "        if cnt%100 == 0: print(\"-\",end=\" \")\n",
    "    return partial, npts, complete\n",
    "\n",
    "partial, npts, complete = get_pcds_np(\"data/complete/\", training=True)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "checkpoint_name = \"cp-{step}.ckpt\"\n",
    "checkpoint_name.format(step=10)\n",
    "os.path.join(\"training\",checkpoint_name.format(step=100))\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(24)\n",
    "print(idx)\n",
    "print(idx[:None])\n",
    "\n",
    "def get_idx(idxs, bs):\n",
    "    ids = []\n",
    "    for i in range(int(np.ceil(len(idxs)/bs))):\n",
    "        start = i*bs\n",
    "        end = None if start+bs >= len(idxs) else start+bs\n",
    "        print(start, end)\n",
    "        ids.append(idxs.tolist()[start:end])\n",
    "    return ids\n",
    "print(get_idx(idx, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, inputs, npts, gt\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "model = PCN()\n",
    "coarse, fine = model((partial,npts), training=True)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_utils.emd import *\n",
    "\n",
    "a = tf.random.normal((3,123,3))\n",
    "b = tf.random.normal((3,123,3))\n",
    "\n",
    "print( getEMD(a.numpy(),b.numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_conv(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(channels[0], 1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(channels[1], 1, activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def mlp(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(channels[0], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[2], activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def point_maxpool(inputs, npts, keepdims=False):\n",
    "    outputs = [tf.reduce_max(f, axis=1, keepdims=keepdims)\n",
    "        for f in tf.split(inputs, npts, axis=1)]\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def point_unpool(inputs, npts):\n",
    "    inputs = tf.split(inputs, inputs.shape[0], axis=0)\n",
    "    outputs = [tf.tile(f, [1, npts[i], 1]) for i,f in enumerate(inputs)]\n",
    "    return tf.concat(outputs, axis=1)\n",
    "\n",
    "# npts = [1024,1024,1024]\n",
    "# x = tf.random.normal((3,1024,3))\n",
    "# pprint(\"Input Tensor\", x.shape)\n",
    "# x = tf.reshape(x, [1, x.shape[1]*x.shape[0], 3])\n",
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (aft reshaping)\", x.shape)\n",
    "features = mlp_conv(x,[64,128])\n",
    "pprint(\"Output Tensor (aft Conv1D)\", features.shape)\n",
    "\n",
    "features_1 = point_maxpool(features, npts, keepdims=1)\n",
    "pprint(\"Output Tensor (aft maxpool)\", features_1.shape)\n",
    "features_global = point_unpool(features_1, npts)\n",
    "pprint(\"Output Tensor (aft unpool)\", features_global.shape)\n",
    "\n",
    "features = tf.concat([features, features_global], axis=2)\n",
    "pprint(\"Output Tensor (aft concat)\", features.shape)\n",
    "\n",
    "features = mlp_conv(features,[512,1024])\n",
    "pprint(\"Output Tensor (aft 2nd conv)\", features.shape)\n",
    "features = point_maxpool(features,npts)\n",
    "pprint(\"Output Tensor (aft 2nd maxpool)\", features.shape)\n",
    "\n",
    "\n",
    "coarse = mlp(features,[1024,1024, 1024*3])\n",
    "pprint(\"Output Tensor (aft MLP)\", coarse.shape)\n",
    "\n",
    "coarse = tf.reshape(coarse, [-1, 1024, 3])\n",
    "pprint(\"Output Tensor (aft reshaping)\", coarse.shape)\n",
    "\n",
    "\"\"\"\n",
    "    Input Tensor (aft reshaping)    : (1, 105, 3)\n",
    "     Output Tensor (aft Conv1D)     : (1, 105, 128)\n",
    "    Output Tensor (aft maxpool)     : (3, 1, 128)\n",
    "     Output Tensor (aft unpool)     : (1, 105, 128)\n",
    "     Output Tensor (aft concat)     : (1, 105, 256)\n",
    "    Output Tensor (aft 2nd conv)    : (1, 105, 1024)\n",
    "  Output Tensor (aft 2nd maxpool)   : (3, 1024)\n",
    "      Output Tensor (aft MLP)       : (3, 3072)\n",
    "   Output Tensor (aft reshaping)    : (3, 1024, 3)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCCN Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Tensor (aft reshaping)      : (1, 105, 3)\n",
    "Output Tensor (aft Conv1D)        : (1, 105, 128)\n",
    "Output Tensor (aft maxpool)       : (3, 1, 128)\n",
    "Output Tensor (aft unpool)        : (1, 105, 128)\n",
    "Output Tensor (aft concat)        : (1, 105, 256)\n",
    "Output Tensor (aft 2nd conv)      : (1, 105, 1024)\n",
    "Output Tensor (aft 2nd maxpool)   : (3, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = tf.random.normal((1,12,3))\n",
    "x = tf.expand_dims(partial, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv2D(5, [1,3], activation='relu')(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "x = tf.expand_dims(partial, axis=-1)\n",
    "pprint(\"Input Tensor (aft expansion)\", x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], padding='valid', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, 1,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(256, 1, activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[105, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3, 1)\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "# Point functions (MLP implemented as conv2d)\n",
    "# By default, Keras version of Conv2D has: strides=[1,1], padding=\"valid\" , data_format=\"channels_last\"\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1],activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(1024, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Symmetric function: max pooling\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[num_pts, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# MLP on global point cloud vector\n",
    "x = tf.reshape(x, [bs, -1])\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n",
    "print(\"Mean:\",mean.shape, \" Log(Var):\",logvar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
