{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 18:50:04.249441: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-22 18:50:04.249472: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "2.6.0\n",
      "0.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from models.pcn import *\n",
    "from models.pccn import *\n",
    "import os\n",
    "import open3d_util\n",
    "\n",
    "print(tf.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "16384\n",
      "(16384, 3)\n"
     ]
    }
   ],
   "source": [
    "def read_pcd(filename):\n",
    "    pcd = o3d.io.read_point_cloud(filename)\n",
    "    return pcd.points\n",
    "\n",
    "test = np.asarray((read_pcd(\"/home/wrs/colab/PCC-Net/data/test/complete/38_0_cubic3_complete.pcd\")))\n",
    "print(type(test))\n",
    "print(len(test))\n",
    "print((test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37684"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([2735, 4630, 837, 8550, 2468, 7598, 6369, 4497])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(s, shape):\n",
    "    print(s.center(35), \":\",shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "len(get_file_paths(\"data/complete/\", training=0))\n",
    "\n",
    "def xform(dir):\n",
    "    return dir.replace(\"complete\", \"partial\")\n",
    "\n",
    "def get_pcds_np(complete_dir, training=True):\n",
    "    partial, npts, complete = [], [], []\n",
    "    cnt = 0\n",
    "    for pcd_path in get_file_paths(complete_dir, training=True):\n",
    "        complete.append(open3d_util.read_pcd(os.path.join(complete_dir, pcd_path)))\n",
    "        partial.append(open3d_util.read_pcd(os.path.join(xform(complete_dir), xform(pcd_path))))\n",
    "        npts.append(len(partial[-1]))\n",
    "        cnt+=1\n",
    "        if cnt%100 == 0: print(\"-\",end=\" \")\n",
    "    return partial, npts, complete\n",
    "\n",
    "partial, npts, complete = get_pcds_np(\"data/complete/\", training=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import Dataloader\n",
    "ds_train = Dataloader(complete_dir=\"data/complete/\", is_training=True, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_train.counter)\n",
    "d = iter(ds_train)\n",
    "a,b,c = next(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_train.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    t = 0\n",
    "    for i,ele in enumerate(d):\n",
    "        print(\"-\",end=\" \")\n",
    "        t+=len(ele[1])\n",
    "    print(\"\\n\",t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = iter(ds_train)\n",
    "for i in d:\n",
    "    print(\"-\",end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(ds_train)\n",
    "\n",
    "# Using next to get to the next iterator element\n",
    "print(next(i))\n",
    "print(next(i))\n",
    "print(next(i))\n",
    "print(next(i))\n",
    "print(next(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(24)\n",
    "print(idx)\n",
    "print(idx[:None])\n",
    "\n",
    "def get_idx(idxs, bs):\n",
    "    ids = []\n",
    "    for i in range(int(np.ceil(len(idxs)/bs))):\n",
    "        start = i*bs\n",
    "        end = None if start+bs >= len(idxs) else start+bs\n",
    "        print(start, end)\n",
    "        ids.append(idxs.tolist()[start:end])\n",
    "    return ids\n",
    "print(get_idx(idx, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, inputs, npts, gt\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "model = PCN()\n",
    "coarse, fine = model((partial,npts), training=True)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_utils.emd import *\n",
    "\n",
    "a = tf.random.normal((3,123,3))\n",
    "b = tf.random.normal((3,123,3))\n",
    "\n",
    "print( getEMD(a.numpy(),b.numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_conv(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(channels[0], 1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(channels[1], 1, activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def mlp(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(channels[0], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[2], activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def point_maxpool(inputs, npts, keepdims=False):\n",
    "    outputs = [tf.reduce_max(f, axis=1, keepdims=keepdims)\n",
    "        for f in tf.split(inputs, npts, axis=1)]\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def point_unpool(inputs, npts):\n",
    "    inputs = tf.split(inputs, inputs.shape[0], axis=0)\n",
    "    outputs = [tf.tile(f, [1, npts[i], 1]) for i,f in enumerate(inputs)]\n",
    "    return tf.concat(outputs, axis=1)\n",
    "\n",
    "# npts = [1024,1024,1024]\n",
    "# x = tf.random.normal((3,1024,3))\n",
    "# pprint(\"Input Tensor\", x.shape)\n",
    "# x = tf.reshape(x, [1, x.shape[1]*x.shape[0], 3])\n",
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (aft reshaping)\", x.shape)\n",
    "features = mlp_conv(x,[64,128])\n",
    "pprint(\"Output Tensor (aft Conv1D)\", features.shape)\n",
    "\n",
    "features_1 = point_maxpool(features, npts, keepdims=1)\n",
    "pprint(\"Output Tensor (aft maxpool)\", features_1.shape)\n",
    "features_global = point_unpool(features_1, npts)\n",
    "pprint(\"Output Tensor (aft unpool)\", features_global.shape)\n",
    "\n",
    "features = tf.concat([features, features_global], axis=2)\n",
    "pprint(\"Output Tensor (aft concat)\", features.shape)\n",
    "\n",
    "features = mlp_conv(features,[512,1024])\n",
    "pprint(\"Output Tensor (aft 2nd conv)\", features.shape)\n",
    "features = point_maxpool(features,npts)\n",
    "pprint(\"Output Tensor (aft 2nd maxpool)\", features.shape)\n",
    "\n",
    "\n",
    "coarse = mlp(features,[1024,1024, 1024*3])\n",
    "pprint(\"Output Tensor (aft MLP)\", coarse.shape)\n",
    "\n",
    "coarse = tf.reshape(coarse, [-1, 1024, 3])\n",
    "pprint(\"Output Tensor (aft reshaping)\", coarse.shape)\n",
    "\n",
    "\"\"\"\n",
    "    Input Tensor (aft reshaping)    : (1, 105, 3)\n",
    "     Output Tensor (aft Conv1D)     : (1, 105, 128)\n",
    "    Output Tensor (aft maxpool)     : (3, 1, 128)\n",
    "     Output Tensor (aft unpool)     : (1, 105, 128)\n",
    "     Output Tensor (aft concat)     : (1, 105, 256)\n",
    "    Output Tensor (aft 2nd conv)    : (1, 105, 1024)\n",
    "  Output Tensor (aft 2nd maxpool)   : (3, 1024)\n",
    "      Output Tensor (aft MLP)       : (3, 3072)\n",
    "   Output Tensor (aft reshaping)    : (3, 1024, 3)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8, np.random.randint(100), 3, 1)\n",
    "num_output = 8192\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "x = tf.random.normal(input_shape)\n",
    "print(\"Input Tensor (raw):\",x.shape)\n",
    "x = PointNet(x.shape, 128)(x)\n",
    "print(\"Output Tensor (Encoder):\",x.shape)\n",
    "x = MLP()(x)\n",
    "print(\"Output Tensor (Decoder):\",x.shape)\n",
    "\n",
    "x = tf.reshape(x, [bs, 8192, 3])\n",
    "print(\"Final Output:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3,1)\n",
    "x = tf.random.normal(input_shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3, 1)\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "# Point functions (MLP implemented as conv2d)\n",
    "# By default, Keras version of Conv2D has: strides=[1,1], padding=\"valid\" , data_format=\"channels_last\"\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1],activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(1024, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Symmetric function: max pooling\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[num_pts, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# MLP on global point cloud vector\n",
    "x = tf.reshape(x, [bs, -1])\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n",
    "print(\"Mean:\",mean.shape, \" Log(Var):\",logvar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
