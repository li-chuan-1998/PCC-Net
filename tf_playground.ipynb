{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "0.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import util\n",
    "from models.pcn import *\n",
    "from models.pccn import *\n",
    "from models.pointnet import *\n",
    "\n",
    "print(tf.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(s, shape):\n",
    "    print(s.center(35), \":\",shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.48436394, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def distance_matrix(array1, array2):\n",
    "    \"\"\"\n",
    "    arguments: \n",
    "        array1: the array, size: (num_point, num_feature)\n",
    "        array2: the samples, size: (num_point, num_feature)\n",
    "    returns:\n",
    "        distances: each entry is the distance from a sample to array1\n",
    "            , it's size: (num_point, num_point)\n",
    "    \"\"\"\n",
    "    num_point, num_features = array1.shape\n",
    "    expanded_array1 = tf.tile(array1, (num_point, 1))\n",
    "    expanded_array2 = tf.reshape(\n",
    "            tf.tile(tf.expand_dims(array2, 1), \n",
    "                    (1, num_point, 1)),\n",
    "            (-1, num_features))\n",
    "    distances = tf.norm(expanded_array1-expanded_array2, axis=1)\n",
    "    distances = tf.reshape(distances, (num_point, num_point))\n",
    "    return distances\n",
    "\n",
    "def av_dist(array1, array2):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        array1, array2: both size: (num_points, num_feature)\n",
    "    returns:\n",
    "        distances: size: (1,)\n",
    "    \"\"\"\n",
    "    distances = distance_matrix(array1, array2)\n",
    "    distances = tf.reduce_min(distances, axis=1)\n",
    "    distances = tf.reduce_mean(distances)\n",
    "    return distances\n",
    "\n",
    "def av_dist_sum(arrays):\n",
    "    \"\"\"\n",
    "    arguments:\n",
    "        arrays: array1, array2\n",
    "    returns:\n",
    "        sum of av_dist(array1, array2) and av_dist(array2, array1)\n",
    "    \"\"\"\n",
    "    array1, array2 = arrays\n",
    "    av_dist1 = av_dist(array1, array2)\n",
    "    av_dist2 = av_dist(array2, array1)\n",
    "    return av_dist1+av_dist2\n",
    "def chamfer_distance_tf(array1, array2):\n",
    "    batch_size, num_point, num_features = array1.shape\n",
    "    dist = tf.reduce_mean(\n",
    "               tf.map_fn(av_dist_sum, elems=(array1, array2), dtype=tf.float32)\n",
    "           )\n",
    "    return dist\n",
    "\n",
    "a = tf.random.normal((4, 1024,3))\n",
    "b = tf.random.normal((4, 1024,3))\n",
    "result = chamfer_distance_tf(a,b)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Input Tensor (raw):         : (1, 105, 3)\n",
      "    Output Tensor (aft encoder):    : (3, 1024)\n",
      "Output Tensor (aft decoder): coarse--> : (3, 1024, 3)\n",
      "Output Tensor (aft decoder): fine--> : (3, 16384, 3)\n"
     ]
    }
   ],
   "source": [
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (raw):\",x.shape)\n",
    "x = Encoder_PN(npts)(x)\n",
    "pprint(\"Output Tensor (aft encoder):\",x.shape)\n",
    "# x = Coarse_Layer()(x)\n",
    "# pprint(\"Output Tensor (aft coarse):\",x.shape)\n",
    "coarse, fine = Decoder()(x)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)\n",
    "\n",
    "# x = VanillaEncoder()(x)\n",
    "# print(\"Output Tensor (after 2sd PN):\",x.shape)\n",
    "# print(\"Output Tensor (Encoder):\",x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Tensor (aft decoder): coarse--> : (3, 1024, 3)\n",
      "Output Tensor (aft decoder): fine--> : (3, 16384, 3)\n"
     ]
    }
   ],
   "source": [
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "coarse, fine = PCN(npts)(x)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_conv(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(channels[0], 1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(channels[1], 1, activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def mlp(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(channels[0], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[2], activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def point_maxpool(inputs, npts, keepdims=False):\n",
    "    outputs = [tf.reduce_max(f, axis=1, keepdims=keepdims)\n",
    "        for f in tf.split(inputs, npts, axis=1)]\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def point_unpool(inputs, npts):\n",
    "    inputs = tf.split(inputs, inputs.shape[0], axis=0)\n",
    "    outputs = [tf.tile(f, [1, npts[i], 1]) for i,f in enumerate(inputs)]\n",
    "    return tf.concat(outputs, axis=1)\n",
    "\n",
    "# npts = [1024,1024,1024]\n",
    "# x = tf.random.normal((3,1024,3))\n",
    "# pprint(\"Input Tensor\", x.shape)\n",
    "# x = tf.reshape(x, [1, x.shape[1]*x.shape[0], 3])\n",
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (aft reshaping)\", x.shape)\n",
    "features = mlp_conv(x,[64,128])\n",
    "pprint(\"Output Tensor (aft Conv1D)\", features.shape)\n",
    "\n",
    "features_1 = point_maxpool(features, npts, keepdims=1)\n",
    "pprint(\"Output Tensor (aft maxpool)\", features_1.shape)\n",
    "features_global = point_unpool(features_1, npts)\n",
    "pprint(\"Output Tensor (aft unpool)\", features_global.shape)\n",
    "\n",
    "features = tf.concat([features, features_global], axis=2)\n",
    "pprint(\"Output Tensor (aft concat)\", features.shape)\n",
    "\n",
    "features = mlp_conv(features,[512,1024])\n",
    "pprint(\"Output Tensor (aft 2nd conv)\", features.shape)\n",
    "features = point_maxpool(features,npts)\n",
    "pprint(\"Output Tensor (aft 2nd maxpool)\", features.shape)\n",
    "\n",
    "\n",
    "coarse = mlp(features,[1024,1024, 1024*3])\n",
    "pprint(\"Output Tensor (aft MLP)\", coarse.shape)\n",
    "\n",
    "coarse = tf.reshape(coarse, [-1, 1024, 3])\n",
    "pprint(\"Output Tensor (aft reshaping)\", coarse.shape)\n",
    "\n",
    "\"\"\"\n",
    "    Input Tensor (aft reshaping)    : (1, 105, 3)\n",
    "     Output Tensor (aft Conv1D)     : (1, 105, 128)\n",
    "    Output Tensor (aft maxpool)     : (3, 1, 128)\n",
    "     Output Tensor (aft unpool)     : (1, 105, 128)\n",
    "     Output Tensor (aft concat)     : (1, 105, 256)\n",
    "    Output Tensor (aft 2nd conv)    : (1, 105, 1024)\n",
    "  Output Tensor (aft 2nd maxpool)   : (3, 1024)\n",
    "      Output Tensor (aft MLP)       : (3, 3072)\n",
    "   Output Tensor (aft reshaping)    : (3, 1024, 3)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8, np.random.randint(100), 3, 1)\n",
    "num_output = 8192\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "x = tf.random.normal(input_shape)\n",
    "print(\"Input Tensor (raw):\",x.shape)\n",
    "x = PointNet(x.shape, 128)(x)\n",
    "print(\"Output Tensor (Encoder):\",x.shape)\n",
    "x = MLP()(x)\n",
    "print(\"Output Tensor (Decoder):\",x.shape)\n",
    "\n",
    "x = tf.reshape(x, [bs, 8192, 3])\n",
    "print(\"Final Output:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3,1)\n",
    "x = tf.random.normal(input_shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3, 1)\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "# Point functions (MLP implemented as conv2d)\n",
    "# By default, Keras version of Conv2D has: strides=[1,1], padding=\"valid\" , data_format=\"channels_last\"\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1],activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(1024, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Symmetric function: max pooling\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[num_pts, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# MLP on global point cloud vector\n",
    "x = tf.reshape(x, [bs, -1])\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n",
    "print(\"Mean:\",mean.shape, \" Log(Var):\",logvar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
