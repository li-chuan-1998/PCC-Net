{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from models.pcn import *\n",
    "from models.pccn import *\n",
    "import os\n",
    "import open3d_util\n",
    "\n",
    "print(tf.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagenerator import DataGenerator\n",
    "\n",
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "complete_dir = \"data/complete/\"\n",
    "ds_train = DataGenerator(get_file_paths(complete_dir), complete_dir)\n",
    "print(len(ds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True True "
     ]
    }
   ],
   "source": [
    "for idx, (inputs, gt) in enumerate(ds_train):\n",
    "    print(sum(inputs[1]) == inputs[0].shape[1], end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2) 3\n",
      "1 2\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    return (1, 2), 3\n",
    "a, b = foo()\n",
    "print(a, b)\n",
    "q,w = a\n",
    "print(q,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_valid.list_pcd_path)//8)\n",
    "c = 0\n",
    "for id, data in enumerate(ds_valid):\n",
    "    assert sum(data[1]) == data[0].shape[1]\n",
    "    c+=1\n",
    "    if c % 10: print(\"-\",end=\" \")\n",
    "    # print(data[0].shape, end=\" | \")\n",
    "print(c, ds_iter.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataloader import Dataloader\n",
    "ds_train = Dataloader(complete_dir=\"data/complete/\", is_training=True, batch_size=1)\n",
    "ds_train = tf.data.Dataset.from_generator(ds_train, output_types=(tf.float32, tf.int32, tf.float32), output_shapes=((), (), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_old import Dataloader\n",
    "ds_train = Dataloader(\"data/complete/\", is_training=False)\n",
    "a, b, c = ds_train.split_to_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "q, w, e = tf.convert_to_tensor(a), tf.convert_to_tensor(b), tf.convert_to_tensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pcn import PCN\n",
    "model = PCN()\n",
    "model.build(input_shape=(1,None,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(s, shape):\n",
    "    print(s.center(35), \":\",shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "len(get_file_paths(\"data/complete/\", training=0))\n",
    "\n",
    "def xform(dir):\n",
    "    return dir.replace(\"complete\", \"partial\")\n",
    "\n",
    "def get_pcds_np(complete_dir, training=True):\n",
    "    partial, npts, complete = [], [], []\n",
    "    cnt = 0\n",
    "    for pcd_path in get_file_paths(complete_dir, training=True):\n",
    "        complete.append(open3d_util.read_pcd(os.path.join(complete_dir, pcd_path)))\n",
    "        partial.append(open3d_util.read_pcd(os.path.join(xform(complete_dir), xform(pcd_path))))\n",
    "        npts.append(len(partial[-1]))\n",
    "        cnt+=1\n",
    "        if cnt%100 == 0: print(\"-\",end=\" \")\n",
    "    return partial, npts, complete\n",
    "\n",
    "partial, npts, complete = get_pcds_np(\"data/complete/\", training=True)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "checkpoint_name = \"cp-{step}.ckpt\"\n",
    "checkpoint_name.format(step=10)\n",
    "os.path.join(\"training\",checkpoint_name.format(step=100))\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(24)\n",
    "print(idx)\n",
    "print(idx[:None])\n",
    "\n",
    "def get_idx(idxs, bs):\n",
    "    ids = []\n",
    "    for i in range(int(np.ceil(len(idxs)/bs))):\n",
    "        start = i*bs\n",
    "        end = None if start+bs >= len(idxs) else start+bs\n",
    "        print(start, end)\n",
    "        ids.append(idxs.tolist()[start:end])\n",
    "    return ids\n",
    "print(get_idx(idx, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, inputs, npts, gt\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "model = PCN()\n",
    "coarse, fine = model((partial,npts), training=True)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_utils.emd import *\n",
    "\n",
    "a = tf.random.normal((3,123,3))\n",
    "b = tf.random.normal((3,123,3))\n",
    "\n",
    "print( getEMD(a.numpy(),b.numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_conv(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(channels[0], 1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(channels[1], 1, activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def mlp(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(channels[0], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[2], activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def point_maxpool(inputs, npts, keepdims=False):\n",
    "    outputs = [tf.reduce_max(f, axis=1, keepdims=keepdims)\n",
    "        for f in tf.split(inputs, npts, axis=1)]\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def point_unpool(inputs, npts):\n",
    "    inputs = tf.split(inputs, inputs.shape[0], axis=0)\n",
    "    outputs = [tf.tile(f, [1, npts[i], 1]) for i,f in enumerate(inputs)]\n",
    "    return tf.concat(outputs, axis=1)\n",
    "\n",
    "# npts = [1024,1024,1024]\n",
    "# x = tf.random.normal((3,1024,3))\n",
    "# pprint(\"Input Tensor\", x.shape)\n",
    "# x = tf.reshape(x, [1, x.shape[1]*x.shape[0], 3])\n",
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (aft reshaping)\", x.shape)\n",
    "features = mlp_conv(x,[64,128])\n",
    "pprint(\"Output Tensor (aft Conv1D)\", features.shape)\n",
    "\n",
    "features_1 = point_maxpool(features, npts, keepdims=1)\n",
    "pprint(\"Output Tensor (aft maxpool)\", features_1.shape)\n",
    "features_global = point_unpool(features_1, npts)\n",
    "pprint(\"Output Tensor (aft unpool)\", features_global.shape)\n",
    "\n",
    "features = tf.concat([features, features_global], axis=2)\n",
    "pprint(\"Output Tensor (aft concat)\", features.shape)\n",
    "\n",
    "features = mlp_conv(features,[512,1024])\n",
    "pprint(\"Output Tensor (aft 2nd conv)\", features.shape)\n",
    "features = point_maxpool(features,npts)\n",
    "pprint(\"Output Tensor (aft 2nd maxpool)\", features.shape)\n",
    "\n",
    "\n",
    "coarse = mlp(features,[1024,1024, 1024*3])\n",
    "pprint(\"Output Tensor (aft MLP)\", coarse.shape)\n",
    "\n",
    "coarse = tf.reshape(coarse, [-1, 1024, 3])\n",
    "pprint(\"Output Tensor (aft reshaping)\", coarse.shape)\n",
    "\n",
    "\"\"\"\n",
    "    Input Tensor (aft reshaping)    : (1, 105, 3)\n",
    "     Output Tensor (aft Conv1D)     : (1, 105, 128)\n",
    "    Output Tensor (aft maxpool)     : (3, 1, 128)\n",
    "     Output Tensor (aft unpool)     : (1, 105, 128)\n",
    "     Output Tensor (aft concat)     : (1, 105, 256)\n",
    "    Output Tensor (aft 2nd conv)    : (1, 105, 1024)\n",
    "  Output Tensor (aft 2nd maxpool)   : (3, 1024)\n",
    "      Output Tensor (aft MLP)       : (3, 3072)\n",
    "   Output Tensor (aft reshaping)    : (3, 1024, 3)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCCN Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Tensor (aft reshaping)      : (1, 105, 3)\n",
    "Output Tensor (aft Conv1D)        : (1, 105, 128)\n",
    "Output Tensor (aft maxpool)       : (3, 1, 128)\n",
    "Output Tensor (aft unpool)        : (1, 105, 128)\n",
    "Output Tensor (aft concat)        : (1, 105, 256)\n",
    "Output Tensor (aft 2nd conv)      : (1, 105, 1024)\n",
    "Output Tensor (aft 2nd maxpool)   : (3, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = tf.random.normal((1,12,3))\n",
    "x = tf.expand_dims(partial, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv2D(5, [1,3], activation='relu')(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "x = tf.expand_dims(partial, axis=-1)\n",
    "pprint(\"Input Tensor (aft expansion)\", x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], padding='valid', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, 1,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(256, 1, activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[105, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3, 1)\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "# Point functions (MLP implemented as conv2d)\n",
    "# By default, Keras version of Conv2D has: strides=[1,1], padding=\"valid\" , data_format=\"channels_last\"\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1],activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(1024, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Symmetric function: max pooling\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[num_pts, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# MLP on global point cloud vector\n",
    "x = tf.reshape(x, [bs, -1])\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n",
    "print(\"Mean:\",mean.shape, \" Log(Var):\",logvar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
