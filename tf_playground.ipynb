{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from models.pcn import *\n",
    "from models.pccn import *\n",
    "import os\n",
    "import open3d_util\n",
    "\n",
    "print(tf.__version__)\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datagenerator import DataGenerator\n",
    "\n",
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "complete_dir = \"data/complete/\"\n",
    "ds_train = DataGenerator(get_file_paths(complete_dir), complete_dir)\n",
    "print((ds_train[2][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_2 import Dataloader\n",
    "complete_dir = \"data/complete/\"\n",
    "ds_valid = Dataloader(complete_dir, is_training=False, batch_size=8)\n",
    "print(ds_valid.counter)\n",
    "ds_iter = iter(ds_valid)\n",
    "# batch = next(ds_iter)\n",
    "# print(batch[0].shape,batch[1],batch[2].shape)\n",
    "# print(sum(batch[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ds_valid.list_pcd_path)//8)\n",
    "c = 0\n",
    "for id, data in enumerate(ds_valid):\n",
    "    assert sum(data[1]) == data[0].shape[1]\n",
    "    c+=1\n",
    "    if c % 10: print(\"-\",end=\" \")\n",
    "    # print(data[0].shape, end=\" | \")\n",
    "print(c, ds_iter.counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Geek:\n",
    "    def __call__(self):\n",
    "        print('Hello GeeksforGeeks')\n",
    "\n",
    "geek = Geek()\n",
    "geek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataloader import Dataloader\n",
    "ds_train = Dataloader(complete_dir=\"data/complete/\", is_training=True, batch_size=1)\n",
    "ds_train = tf.data.Dataset.from_generator(ds_train, output_types=(tf.float32, tf.int32, tf.float32), output_shapes=((), (), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (a,b,c) in ds_train.repeat().batch(8).take(10):\n",
    "    print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = [100, 200, 500]\n",
    "b = [0.01, 0.1, 0.5, 1.0]\n",
    "\n",
    "def get_alpha(step):\n",
    "    for ind, ele in enumerate(rng):\n",
    "        if step < ele:\n",
    "            return b[ind]\n",
    "    return b[-1]\n",
    "\n",
    "\n",
    "print(get_alpha(12))\n",
    "print(get_alpha(122))\n",
    "print(get_alpha(222))\n",
    "print(get_alpha(400))\n",
    "print(get_alpha(533))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 21:34:09.083096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:09.083125: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - \n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 21:34:25.346474: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.346593: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.346691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.346786: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.346881: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.346976: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.347068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/extras/CUPTI/lib64\n",
      "2022-07-26 21:34:25.347301: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-26 21:34:25.347815: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from dataloader_old import Dataloader\n",
    "ds_train = Dataloader(\"data/complete/\", is_training=False)\n",
    "a, b, c = ds_train.split_to_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shapes of all inputs must match: values[0].shape = [1,35241,3] != values[1].shape = [1,40404,3] [Op:Pack] name: packed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/wrs/colab/PCC-Net/tf_playground.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/wrs/colab/PCC-Net/tf_playground.ipynb#ch0000029?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/wrs/colab/PCC-Net/tf_playground.ipynb#ch0000029?line=1'>2</a>\u001b[0m q, w, e \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(a), tf\u001b[39m.\u001b[39mconvert_to_tensor(b), tf\u001b[39m.\u001b[39mconvert_to_tensor(c)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1430\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m   1367\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m   1368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1370\u001b[0m   \u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m   1371\u001b[0m \n\u001b[1;32m   1372\u001b[0m \u001b[39m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[39m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1430\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[1;32m   1431\u001b[0m       value, dtype\u001b[39m=\u001b[39;49mdtype, dtype_hint\u001b[39m=\u001b[39;49mdtype_hint, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1436\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1435\u001b[0m   \u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1436\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor(\n\u001b[1;32m   1437\u001b[0m       value\u001b[39m=\u001b[39;49mvalue,\n\u001b[1;32m   1438\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1439\u001b[0m       name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   1440\u001b[0m       preferred_dtype\u001b[39m=\u001b[39;49mdtype_hint,\n\u001b[1;32m   1441\u001b[0m       as_ref\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1561\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1562\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1563\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[1;32m   1565\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1566\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1568\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1569\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1537\u001b[0m, in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39melif\u001b[39;00m dtype \u001b[39m!=\u001b[39m inferred_dtype:\n\u001b[1;32m   1536\u001b[0m   v \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(_cast_nested_seqs_to_dtype(dtype), v)\n\u001b[0;32m-> 1537\u001b[0m \u001b[39mreturn\u001b[39;00m _autopacking_helper(v, dtype, name \u001b[39mor\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mpacked\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1443\u001b[0m, in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m   1440\u001b[0m   \u001b[39m# NOTE: Fast path when all the items are tensors, this doesn't do any type\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m   \u001b[39m# checking.\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(elem, core\u001b[39m.\u001b[39mTensor) \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m list_or_tuple):\n\u001b[0;32m-> 1443\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mpack(list_or_tuple, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1444\u001b[0m must_pack \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m converted_elems \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py:6383\u001b[0m, in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   6381\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   6382\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 6383\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   6384\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   6385\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:6941\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6939\u001b[0m message \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6940\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 6941\u001b[0m six\u001b[39m.\u001b[39;49mraise_from(core\u001b[39m.\u001b[39;49m_status_to_exception(e\u001b[39m.\u001b[39;49mcode, message), \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes of all inputs must match: values[0].shape = [1,35241,3] != values[1].shape = [1,40404,3] [Op:Pack] name: packed"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "q, w, e = tf.convert_to_tensor(a), tf.convert_to_tensor(b), tf.convert_to_tensor(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
     ]
    }
   ],
   "source": [
    "from models.pcn import PCN\n",
    "model = PCN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(s, shape):\n",
    "    print(s.center(35), \":\",shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCN Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(complete_dir, training=True):\n",
    "    mid_pt = int(len(os.listdir(complete_dir))*7/9)\n",
    "    start = 0 if training else mid_pt\n",
    "    end = mid_pt if training else None\n",
    "    return sorted(os.listdir(complete_dir))[start:end]\n",
    "\n",
    "len(get_file_paths(\"data/complete/\", training=0))\n",
    "\n",
    "def xform(dir):\n",
    "    return dir.replace(\"complete\", \"partial\")\n",
    "\n",
    "def get_pcds_np(complete_dir, training=True):\n",
    "    partial, npts, complete = [], [], []\n",
    "    cnt = 0\n",
    "    for pcd_path in get_file_paths(complete_dir, training=True):\n",
    "        complete.append(open3d_util.read_pcd(os.path.join(complete_dir, pcd_path)))\n",
    "        partial.append(open3d_util.read_pcd(os.path.join(xform(complete_dir), xform(pcd_path))))\n",
    "        npts.append(len(partial[-1]))\n",
    "        cnt+=1\n",
    "        if cnt%100 == 0: print(\"-\",end=\" \")\n",
    "    return partial, npts, complete\n",
    "\n",
    "partial, npts, complete = get_pcds_np(\"data/complete/\", training=True)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "checkpoint_name = \"cp-{step}.ckpt\"\n",
    "checkpoint_name.format(step=10)\n",
    "os.path.join(\"training\",checkpoint_name.format(step=100))\n",
    "\n",
    "a = [i for i in range(10)]\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(24)\n",
    "print(idx)\n",
    "print(idx[:None])\n",
    "\n",
    "def get_idx(idxs, bs):\n",
    "    ids = []\n",
    "    for i in range(int(np.ceil(len(idxs)/bs))):\n",
    "        start = i*bs\n",
    "        end = None if start+bs >= len(idxs) else start+bs\n",
    "        print(start, end)\n",
    "        ids.append(idxs.tolist()[start:end])\n",
    "    return ids\n",
    "print(get_idx(idx, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids, inputs, npts, gt\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "model = PCN()\n",
    "coarse, fine = model((partial,npts), training=True)\n",
    "pprint(\"Output Tensor (aft decoder): coarse-->\", coarse.shape)\n",
    "pprint(\"Output Tensor (aft decoder): fine-->\", fine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_utils.emd import *\n",
    "\n",
    "a = tf.random.normal((3,123,3))\n",
    "b = tf.random.normal((3,123,3))\n",
    "\n",
    "print( getEMD(a.numpy(),b.numpy()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_conv(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(channels[0], 1, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(channels[1], 1, activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def mlp(inputs, channels):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(channels[0], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[1], activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(channels[2], activation='relu'))\n",
    "    outputs = model(inputs)\n",
    "    return outputs\n",
    "\n",
    "def point_maxpool(inputs, npts, keepdims=False):\n",
    "    outputs = [tf.reduce_max(f, axis=1, keepdims=keepdims)\n",
    "        for f in tf.split(inputs, npts, axis=1)]\n",
    "    return tf.concat(outputs, axis=0)\n",
    "\n",
    "\n",
    "def point_unpool(inputs, npts):\n",
    "    inputs = tf.split(inputs, inputs.shape[0], axis=0)\n",
    "    outputs = [tf.tile(f, [1, npts[i], 1]) for i,f in enumerate(inputs)]\n",
    "    return tf.concat(outputs, axis=1)\n",
    "\n",
    "# npts = [1024,1024,1024]\n",
    "# x = tf.random.normal((3,1024,3))\n",
    "# pprint(\"Input Tensor\", x.shape)\n",
    "# x = tf.reshape(x, [1, x.shape[1]*x.shape[0], 3])\n",
    "npts = [20, 30, 55]\n",
    "x = tf.random.normal((1,105,3))\n",
    "pprint(\"Input Tensor (aft reshaping)\", x.shape)\n",
    "features = mlp_conv(x,[64,128])\n",
    "pprint(\"Output Tensor (aft Conv1D)\", features.shape)\n",
    "\n",
    "features_1 = point_maxpool(features, npts, keepdims=1)\n",
    "pprint(\"Output Tensor (aft maxpool)\", features_1.shape)\n",
    "features_global = point_unpool(features_1, npts)\n",
    "pprint(\"Output Tensor (aft unpool)\", features_global.shape)\n",
    "\n",
    "features = tf.concat([features, features_global], axis=2)\n",
    "pprint(\"Output Tensor (aft concat)\", features.shape)\n",
    "\n",
    "features = mlp_conv(features,[512,1024])\n",
    "pprint(\"Output Tensor (aft 2nd conv)\", features.shape)\n",
    "features = point_maxpool(features,npts)\n",
    "pprint(\"Output Tensor (aft 2nd maxpool)\", features.shape)\n",
    "\n",
    "\n",
    "coarse = mlp(features,[1024,1024, 1024*3])\n",
    "pprint(\"Output Tensor (aft MLP)\", coarse.shape)\n",
    "\n",
    "coarse = tf.reshape(coarse, [-1, 1024, 3])\n",
    "pprint(\"Output Tensor (aft reshaping)\", coarse.shape)\n",
    "\n",
    "\"\"\"\n",
    "    Input Tensor (aft reshaping)    : (1, 105, 3)\n",
    "     Output Tensor (aft Conv1D)     : (1, 105, 128)\n",
    "    Output Tensor (aft maxpool)     : (3, 1, 128)\n",
    "     Output Tensor (aft unpool)     : (1, 105, 128)\n",
    "     Output Tensor (aft concat)     : (1, 105, 256)\n",
    "    Output Tensor (aft 2nd conv)    : (1, 105, 1024)\n",
    "  Output Tensor (aft 2nd maxpool)   : (3, 1024)\n",
    "      Output Tensor (aft MLP)       : (3, 3072)\n",
    "   Output Tensor (aft reshaping)    : (3, 1024, 3)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCCN Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Tensor (aft reshaping)      : (1, 105, 3)\n",
    "Output Tensor (aft Conv1D)        : (1, 105, 128)\n",
    "Output Tensor (aft maxpool)       : (3, 1, 128)\n",
    "Output Tensor (aft unpool)        : (1, 105, 128)\n",
    "Output Tensor (aft concat)        : (1, 105, 256)\n",
    "Output Tensor (aft 2nd conv)      : (1, 105, 1024)\n",
    "Output Tensor (aft 2nd maxpool)   : (3, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = tf.random.normal((1,12,3))\n",
    "x = tf.expand_dims(partial, axis=0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv2D(5, [1,3], activation='relu')(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "npts = [20, 30, 55]\n",
    "partial = tf.random.normal((1,105,3))\n",
    "complete = tf.random.normal((3,16384,3))\n",
    "\n",
    "x = tf.expand_dims(partial, axis=-1)\n",
    "pprint(\"Input Tensor (aft expansion)\", x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], padding='valid', activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, 1,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(256, 1, activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[105, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (12, 189, 3, 1)\n",
    "bs = input_shape[0]\n",
    "num_pts = input_shape[1]\n",
    "\n",
    "# Point functions (MLP implemented as conv2d)\n",
    "# By default, Keras version of Conv2D has: strides=[1,1], padding=\"valid\" , data_format=\"channels_last\"\n",
    "x = tf.random.normal(input_shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,3], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1],activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(64, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(128, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Conv2D(1024, [1,1], activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Symmetric function: max pooling\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=[num_pts, 1], strides=(2, 2), padding='valid')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# MLP on global point cloud vector\n",
    "x = tf.reshape(x, [bs, -1])\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(256,activation='relu')(x)\n",
    "print(x.shape)\n",
    "\n",
    "mean, logvar = tf.split(x, num_or_size_splits=2, axis=1)\n",
    "print(\"Mean:\",mean.shape, \" Log(Var):\",logvar.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
